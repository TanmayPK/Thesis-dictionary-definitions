{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset as HFDataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sentencepiece\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and model for baseline testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data for testing\n",
    "data_file_path = 'Data/definitions_dataset/test.json'\n",
    "\n",
    "with open(data_file_path, 'r', encoding='utf-8') as data_file:\n",
    "    test_json_data = json.load(data_file)\n",
    "\n",
    "flattened_json_data = [{'Word': sublist[0][0], 'Definition': ' '.join(sublist[1]), 'Context': ' '.join(sublist[2])}\n",
    "                       for sublist in test_json_data]\n",
    "dft = pd.DataFrame(flattened_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>press</td>\n",
       "      <td>place between two surfaces and apply weight or...</td>\n",
       "      <td>pressed flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glade</td>\n",
       "      <td>an open space in a wood or forest</td>\n",
       "      <td>she found herself lying on her back , cushione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>take</td>\n",
       "      <td>receive ( a specified amount of money ) as pay...</td>\n",
       "      <td>that means that the government spends less mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fattiness</td>\n",
       "      <td>having the property of containing fat</td>\n",
       "      <td>he recommended exercise to reduce my adiposity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dramatisation</td>\n",
       "      <td>conversion into dramatic form</td>\n",
       "      <td>the play was a dramatization of a short story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word                                         Definition  \\\n",
       "0          press  place between two surfaces and apply weight or...   \n",
       "1          glade                  an open space in a wood or forest   \n",
       "2           take  receive ( a specified amount of money ) as pay...   \n",
       "3      fattiness              having the property of containing fat   \n",
       "4  dramatisation                      conversion into dramatic form   \n",
       "\n",
       "                                             Context  \n",
       "0                                    pressed flowers  \n",
       "1  she found herself lying on her back , cushione...  \n",
       "2  that means that the government spends less mon...  \n",
       "3     he recommended exercise to reduce my adiposity  \n",
       "4      the play was a dramatization of a short story  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# lemmatizing occurances of words to match.\n",
    "def word_in_context(word, context):\n",
    "    context_lower = context.lower()\n",
    "    if word in context_lower.split():\n",
    "        return True\n",
    "    root_word = lemmatizer.lemmatize(word)\n",
    "    if root_word in context_lower.split():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "filtered_dft = dft[dft.apply(lambda row: word_in_context(row['Word'], row['Context']), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glade</td>\n",
       "      <td>an open space in a wood or forest</td>\n",
       "      <td>she found herself lying on her back , cushione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>collapse</td>\n",
       "      <td>( of a price or currency ) drop suddenly in value</td>\n",
       "      <td>institutions are rejecting warnings that house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>birch</td>\n",
       "      <td>a formal punishment in which a person is flogg...</td>\n",
       "      <td>are n't there times when you 're tempted to br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drive</td>\n",
       "      <td>( in ball games ) a forceful stroke made with ...</td>\n",
       "      <td>another 30-yard run from the dangerous jamaica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>electrometer</td>\n",
       "      <td>an instrument for measuring electrical potenti...</td>\n",
       "      <td>shortly after antoine becquerel and others dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>jadeite</td>\n",
       "      <td>a green , blue , or white mineral which is one...</td>\n",
       "      <td>in particular , it would have been good to inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12311</th>\n",
       "      <td>curious</td>\n",
       "      <td>strange ; unusual</td>\n",
       "      <td>the best illustration of this strange reversal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>debenture</td>\n",
       "      <td>a long-term security yielding a fixed rate of ...</td>\n",
       "      <td>in return , gary wanted security by way of a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12314</th>\n",
       "      <td>queue</td>\n",
       "      <td>a line or sequence of people or vehicles await...</td>\n",
       "      <td>given its location there should be a queue of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12316</th>\n",
       "      <td>productivity</td>\n",
       "      <td>the rate of production of new biomass by an in...</td>\n",
       "      <td>in other words , there is an optimum leaf quan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word                                         Definition  \\\n",
       "1             glade                  an open space in a wood or forest   \n",
       "6          collapse  ( of a price or currency ) drop suddenly in value   \n",
       "9             birch  a formal punishment in which a person is flogg...   \n",
       "14            drive  ( in ball games ) a forceful stroke made with ...   \n",
       "16     electrometer  an instrument for measuring electrical potenti...   \n",
       "...             ...                                                ...   \n",
       "12309       jadeite  a green , blue , or white mineral which is one...   \n",
       "12311       curious                                  strange ; unusual   \n",
       "12313     debenture  a long-term security yielding a fixed rate of ...   \n",
       "12314         queue  a line or sequence of people or vehicles await...   \n",
       "12316  productivity  the rate of production of new biomass by an in...   \n",
       "\n",
       "                                                 Context  \n",
       "1      she found herself lying on her back , cushione...  \n",
       "6      institutions are rejecting warnings that house...  \n",
       "9      are n't there times when you 're tempted to br...  \n",
       "14     another 30-yard run from the dangerous jamaica...  \n",
       "16     shortly after antoine becquerel and others dev...  \n",
       "...                                                  ...  \n",
       "12309  in particular , it would have been good to inc...  \n",
       "12311  the best illustration of this strange reversal...  \n",
       "12313  in return , gary wanted security by way of a d...  \n",
       "12314  given its location there should be a queue of ...  \n",
       "12316  in other words , there is an optimum leaf quan...  \n",
       "\n",
       "[6751 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the model for testing\n",
    "model_name='google/mt5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanmay/miniconda3/envs/thesis-torch/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512, legacy = False, fast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HFDataset.from_pandas(filtered_dft, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Word', 'Definition', 'Context', '__index_level_0__'],\n",
       "    num_rows: 6751\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dataset['Word'][:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Context = dataset['Context'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Definition = dataset['Definition'][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [06:12<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using a zero shot prompt to generate definitions from pre-trained model.\n",
    "\n",
    "model_definitions = []\n",
    "\n",
    "for idx, w in tqdm(enumerate(words), total=len(words)):\n",
    "    prompt = f\"\"\"\n",
    "    generate definition for the word based on context: \n",
    "    \n",
    "    Word: '{w}'\n",
    "    \n",
    "    Context: '{Context[idx]}'\n",
    "    \n",
    "    Definition: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation = True, add_special_tokens=True)\n",
    "    \n",
    "    model_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    model_text_output = tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    model_definitions.append(model_text_output)\n",
    "\n",
    "zipped = list(zip(words, model_definitions, Definition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an open space in a wood or forest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Definition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glade'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<extra_id_0> 'glade'.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_definitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<extra_id_0> 'glade'.\",\n",
       " \"<extra_id_0> 'collapse' Context:\",\n",
       " \"<extra_id_0> 'birch'.\",\n",
       " \"<extra_id_0> 'drive' -\",\n",
       " \"<extra_id_0> 'electrometer'.\",\n",
       " \"<extra_id_0>'sweet'.\",\n",
       " \"<extra_id_0> 'dust' Context:\",\n",
       " \"<extra_id_0> 'ping'.\",\n",
       " \"<extra_id_0> 'joint'.\",\n",
       " \"<extra_id_0>'mistress'\",\n",
       " \"<extra_id_0> 'cabinetry'.\",\n",
       " \"<extra_id_0> 'would' would\",\n",
       " \"<extra_id_0>'sharp'.\",\n",
       " '<extra_id_0> zebra zebra zebra',\n",
       " \"<extra_id_0>'semimonthly'\",\n",
       " \"<extra_id_0> 'bramble'.\",\n",
       " \"<extra_id_0> 'joint'.\",\n",
       " \"<extra_id_0>'sirocco'.\",\n",
       " \"<extra_id_0> 'that'.\",\n",
       " \"<extra_id_0> 'terrestrial'\",\n",
       " \"<extra_id_0> 'huntsman'.\",\n",
       " \"<extra_id_0> 'betting'.\",\n",
       " '<extra_id_0> idahoan Definition:',\n",
       " \"<extra_id_0> 'flagging'.\",\n",
       " \"<extra_id_0> 'nursery'.\",\n",
       " \"<extra_id_0> 'discharger'.\",\n",
       " \"<extra_id_0> 'equatorial'\",\n",
       " \"<extra_id_0> 'otorhinolaryngology'\",\n",
       " \"<extra_id_0> 'nightmare'.\",\n",
       " \"<extra_id_0> 'astrophysicist'\",\n",
       " \"<extra_id_0> 'hay'.\",\n",
       " \"<extra_id_0> 'naturalize'.\",\n",
       " \"<extra_id_0> 'faceplate'.\",\n",
       " \"<extra_id_0> 'plaza'.\",\n",
       " \"<extra_id_0> 'traffic'.\",\n",
       " \"<extra_id_0> 'ba'.\",\n",
       " \"<extra_id_0> 'bitter'\",\n",
       " \"<extra_id_0> 'attentiveness'\",\n",
       " \"<extra_id_0> 'coverage'.\",\n",
       " \"<extra_id_0> 'atone'.\",\n",
       " \"<extra_id_0> 'lousy'.\",\n",
       " \"<extra_id_0> 'piggyback'\",\n",
       " \"<extra_id_0>'vendetta'.\",\n",
       " \"<extra_id_0> 'exordium'\",\n",
       " \"<extra_id_0>'miscount'.\",\n",
       " \"<extra_id_0> 'zoonosis'.\",\n",
       " \"<extra_id_0>'shred'\",\n",
       " \"<extra_id_0> 'ecology'.\",\n",
       " \"<extra_id_0> 'finca'.\",\n",
       " \"<extra_id_0> 'dilute'.\",\n",
       " \"<extra_id_0>'snappy'\",\n",
       " \"<extra_id_0> 'opposite'\",\n",
       " \"<extra_id_0> 'brucellosis'\",\n",
       " \"<extra_id_0> 'nanny'.\",\n",
       " \"<extra_id_0>'sweet'.\",\n",
       " \"<extra_id_0> 'winning'.\",\n",
       " \"<extra_id_0> 'fascia'.\",\n",
       " \"<extra_id_0> 'fibrin'\",\n",
       " \"<extra_id_0>'spirit'.\",\n",
       " \"<extra_id_0> 'coupler'.\",\n",
       " \"<extra_id_0>'steatite'\",\n",
       " \"<extra_id_0>'multistage'.\",\n",
       " \"<extra_id_0> 'walk'.\",\n",
       " \"<extra_id_0> 'want'.\",\n",
       " \"<extra_id_0> 'that'.\",\n",
       " \"<extra_id_0> 'bijou' - Definition\",\n",
       " \"<extra_id_0> 'why'.\",\n",
       " \"<extra_id_0> 'nine'.\",\n",
       " \"<extra_id_0> 'acadian'.\",\n",
       " \"<extra_id_0> 'heave'\",\n",
       " \"<extra_id_0>'saddlery'\",\n",
       " \"<extra_id_0> 'winning'.\",\n",
       " \"<extra_id_0> 'peruvian'\",\n",
       " \"<extra_id_0>'second-hand'\",\n",
       " \"<extra_id_0> 'dutchwoman'\",\n",
       " \"<extra_id_0>'side'.\",\n",
       " \"<extra_id_0> 'city' Context\",\n",
       " \"<extra_id_0> 'execution'.\",\n",
       " \"<extra_id_0> 'header' Context:\",\n",
       " \"<extra_id_0> 'pearl' -\",\n",
       " \"<extra_id_0>'singularity'\",\n",
       " \"<extra_id_0>'sumerian'.\",\n",
       " \"<extra_id_0> 'heartbreaker'.\",\n",
       " \"<extra_id_0> 'calculus'.\",\n",
       " \"<extra_id_0> 'archduchess'.\",\n",
       " \"<extra_id_0>'sumerian'.\",\n",
       " \"<extra_id_0>'mag' - Definitions\",\n",
       " \"<extra_id_0> 'deferment'\",\n",
       " \"<extra_id_0> 'bauble'.\",\n",
       " \"<extra_id_0> 'nationality'.\",\n",
       " \"<extra_id_0> 'handcart'\",\n",
       " \"<extra_id_0>'miracle' - Definition\",\n",
       " \"<extra_id_0>'reread'.\",\n",
       " \"<extra_id_0> 'prodigal'.\",\n",
       " \"<extra_id_0>'sandalwood'.\",\n",
       " \"<extra_id_0> 'heart' could not\",\n",
       " \"<extra_id_0> 'whey'.\",\n",
       " \"<extra_id_0> 'triennial'.\",\n",
       " \"<extra_id_0> 'brush' - Definition\",\n",
       " \"<extra_id_0> 'kasha'.\",\n",
       " \"<extra_id_0> 'tableware'.\",\n",
       " \"<extra_id_0> 'pharynx'\",\n",
       " \"<extra_id_0> 'broadcast'.\",\n",
       " \"<extra_id_0> 'roaring'.\",\n",
       " \"<extra_id_0> 'garter'.\",\n",
       " \"<extra_id_0> 'flowage'\",\n",
       " \"<extra_id_0> 'disown'\",\n",
       " \"<extra_id_0> 'dip'.\",\n",
       " \"<extra_id_0> 'circumstances'\",\n",
       " \"<extra_id_0> 'discharger'.\",\n",
       " \"<extra_id_0> 'hernia'.\",\n",
       " \"<extra_id_0> 'flavour'.\",\n",
       " \"<extra_id_0>'sweet'.\",\n",
       " \"<extra_id_0> 'composition'\",\n",
       " \"<extra_id_0> 'high'.\",\n",
       " '<extra_id_0> would would would would',\n",
       " \"<extra_id_0> 'tie-dye'\",\n",
       " \"<extra_id_0> 'protoplast'\",\n",
       " \"<extra_id_0> 'guttering'.\",\n",
       " \"<extra_id_0> 'junk'.\",\n",
       " \"<extra_id_0> 'pluralist'\",\n",
       " \"<extra_id_0> 'baby'.\",\n",
       " \"<extra_id_0>'stadium'.\",\n",
       " \"<extra_id_0> 'asphyxiation'\",\n",
       " \"<extra_id_0>'snafu'\",\n",
       " \"<extra_id_0> 'hijacker'.\",\n",
       " \"<extra_id_0> 'op' could be used\",\n",
       " \"<extra_id_0> 'crime'.\",\n",
       " \"<extra_id_0>'spiky'\",\n",
       " \"<extra_id_0> 'last'.\",\n",
       " \"<extra_id_0> 'junk' - Definition\",\n",
       " \"<extra_id_0> 'down'.\",\n",
       " \"<extra_id_0> 'down'.\",\n",
       " \"<extra_id_0> 'twitch' - Definition\",\n",
       " \"<extra_id_0>'moonshine'.\",\n",
       " \"<extra_id_0> 'heavy'.\",\n",
       " \"<extra_id_0> 'outline' Context:\",\n",
       " \"<extra_id_0> 'pragmatics'.\",\n",
       " \"<extra_id_0> 'carmine'.\",\n",
       " \"<extra_id_0> 'deformation'.\",\n",
       " \"<extra_id_0> 'polarity'.\",\n",
       " \"<extra_id_0> 'honey'.\",\n",
       " \"<extra_id_0> 'lively'\",\n",
       " '<extra_id_0> swell Definition:',\n",
       " \"<extra_id_0> 'implantation'.\",\n",
       " \"<extra_id_0>'side'.\",\n",
       " \"<extra_id_0> 'garb'\",\n",
       " \"<extra_id_0> 'dip'.\",\n",
       " \"<extra_id_0> 'inertial'.\",\n",
       " \"<extra_id_0>'myopia'.\",\n",
       " \"<extra_id_0>'mutualism'.\",\n",
       " \"<extra_id_0> 'trioxide'.\",\n",
       " \"<extra_id_0> 'arachnid'.\",\n",
       " \"<extra_id_0> 'pus'.\",\n",
       " \"<extra_id_0> 'visiting'.\",\n",
       " \"<extra_id_0>'metamorphism'.\",\n",
       " \"<extra_id_0>'modulus'.\",\n",
       " \"<extra_id_0> 'clash'.\",\n",
       " \"<extra_id_0> 'prey' Context\",\n",
       " \"<extra_id_0> 'obsidian'\",\n",
       " \"<extra_id_0> 'pay' -\",\n",
       " \"<extra_id_0> 'wick'.\",\n",
       " \"<extra_id_0> 'fast'.\",\n",
       " \"<extra_id_0> 'equatorial'\",\n",
       " \"<extra_id_0> 'involution'.\",\n",
       " \"<extra_id_0>'standing'.\",\n",
       " \"<extra_id_0> 'leg'.\",\n",
       " \"<extra_id_0> 'outdrive'.\",\n",
       " \"<extra_id_0> 'thermoplastic'\",\n",
       " \"<extra_id_0> 'doctrine'.\",\n",
       " \"<extra_id_0> 'lyric'\",\n",
       " \"<extra_id_0>'sweet'.\",\n",
       " \"<extra_id_0>'spaniel'.\",\n",
       " \"<extra_id_0> 'downpipe'.\",\n",
       " \"<extra_id_0> 'conception'.\",\n",
       " \"<extra_id_0> 'noel'.\",\n",
       " \"<extra_id_0> 'bias'.\",\n",
       " \"<extra_id_0>'monument' -\",\n",
       " \"<extra_id_0> 'flatus'.\",\n",
       " \"<extra_id_0> 'chromatin'.\",\n",
       " \"<extra_id_0> 'dress'.\",\n",
       " \"<extra_id_0>'reason'.\",\n",
       " \"<extra_id_0> 'lively'\",\n",
       " \"<extra_id_0> 'worcester'.\",\n",
       " \"<extra_id_0> 'app'.\",\n",
       " \"<extra_id_0> 'drysuit'.\",\n",
       " \"<extra_id_0>'saucisson'.\",\n",
       " \"<extra_id_0> 'bunting'.\",\n",
       " \"<extra_id_0>'sing-song'\",\n",
       " \"<extra_id_0> 'band'.\",\n",
       " \"<extra_id_0> 'identify'.\",\n",
       " \"<extra_id_0>'scry'\",\n",
       " '<extra_id_0> a foolhardy',\n",
       " \"<extra_id_0> 'dress shoes'\",\n",
       " \"<extra_id_0>'revocation'\",\n",
       " \"<extra_id_0> 'cautery'.\",\n",
       " \"<extra_id_0> 'weigh'\",\n",
       " \"<extra_id_0> 'firm' Context\",\n",
       " \"<extra_id_0> 'academy'.\",\n",
       " \"<extra_id_0>'signatory'.\",\n",
       " \"<extra_id_0>'society'.\",\n",
       " \"<extra_id_0> 'big'.\",\n",
       " \"<extra_id_0> 'allspice'.\",\n",
       " \"<extra_id_0>'shield' could be used\",\n",
       " \"<extra_id_0> 'cline'.\",\n",
       " \"<extra_id_0> 'penny-farthing'\",\n",
       " \"<extra_id_0> 'offset'\",\n",
       " \"<extra_id_0> 'baby'.\",\n",
       " \"<extra_id_0>'soundness'.\",\n",
       " \"<extra_id_0> 'kala-azar'\",\n",
       " \"<extra_id_0>'merry-go-round'\",\n",
       " \"<extra_id_0>'monition'.\",\n",
       " \"<extra_id_0> 'psychology' Context:\",\n",
       " \"<extra_id_0> 'exonuclease'\",\n",
       " \"<extra_id_0> 'dip the sheep\",\n",
       " \"<extra_id_0> 'center'.\",\n",
       " \"<extra_id_0> 'anglo-french'\",\n",
       " \"<extra_id_0> 'drum'.\",\n",
       " \"<extra_id_0> 'deodorize'\",\n",
       " \"<extra_id_0> 'entire' -\",\n",
       " \"<extra_id_0> 'dominance'.\",\n",
       " \"<extra_id_0> 'develop'.\",\n",
       " \"<extra_id_0> 'doom'.\",\n",
       " \"<extra_id_0> 'vasodilation'\",\n",
       " \"<extra_id_0> 'anchoress'\",\n",
       " \"<extra_id_0>'scrub'.\",\n",
       " \"<extra_id_0> 'downtown' Context:\",\n",
       " \"<extra_id_0>'recommendation',\",\n",
       " \"<extra_id_0> 'closure'.\",\n",
       " \"<extra_id_0> 'jeremiad'\",\n",
       " \"<extra_id_0> 'nanosecond'.\",\n",
       " \"<extra_id_0> 'naturalize'.\",\n",
       " \"<extra_id_0> 'hang'.\",\n",
       " \"<extra_id_0> 'xhosa'.\",\n",
       " \"<extra_id_0> 'roofline'.\",\n",
       " \"<extra_id_0>'readiness'.\",\n",
       " \"<extra_id_0>'scavenge'\",\n",
       " \"<extra_id_0>'mandarin' -\",\n",
       " \"<extra_id_0> 'occult'\",\n",
       " \"<extra_id_0> 'universal'.\",\n",
       " \"<extra_id_0> 'zinfandel'\",\n",
       " \"<extra_id_0>'species'.\",\n",
       " \"<extra_id_0> 'broadcast' Context\",\n",
       " \"<extra_id_0> 'absent'.\",\n",
       " \"<extra_id_0> 'bitter'.\",\n",
       " \"<extra_id_0>'sift'.\",\n",
       " \"<extra_id_0>'sweet' -\",\n",
       " \"<extra_id_0> 'down' Context\",\n",
       " \"<extra_id_0> 'weigh'\",\n",
       " \"<extra_id_0> 'high'.\",\n",
       " \"<extra_id_0> 'two-piece'\",\n",
       " \"<extra_id_0>'smack'\",\n",
       " \"<extra_id_0> 'peg' - Definition\",\n",
       " \"<extra_id_0> 'jumpy'.\",\n",
       " \"<extra_id_0> 'homeostasis'\",\n",
       " \"<extra_id_0> 'heavy'.\",\n",
       " \"<extra_id_0> 'winnow'\",\n",
       " \"<extra_id_0> 'loop'.\",\n",
       " \"<extra_id_0> 'pragmatic'.\",\n",
       " \"<extra_id_0> 'carrier'.\",\n",
       " \"<extra_id_0>'minuscule'.\",\n",
       " \"<extra_id_0>'shield' -\",\n",
       " \"<extra_id_0> 'leap'.\",\n",
       " \"<extra_id_0> 'goose-step'\",\n",
       " \"<extra_id_0>'seawater'\",\n",
       " \"<extra_id_0> 'dysplasia'.\",\n",
       " \"<extra_id_0>'menu'.\",\n",
       " \"<extra_id_0> 'inhumanity'.\",\n",
       " \"<extra_id_0> 'abate'.\",\n",
       " \"<extra_id_0>'slacker'\",\n",
       " \"<extra_id_0>'stark'.\",\n",
       " \"<extra_id_0>'stab'.\",\n",
       " \"<extra_id_0> 'domination'.\",\n",
       " \"<extra_id_0> 'high'.\",\n",
       " \"<extra_id_0> 'flip'.\",\n",
       " \"<extra_id_0>'refresher'.\",\n",
       " \"<extra_id_0>'see'.\",\n",
       " \"<extra_id_0> 'quahog'.\",\n",
       " \"<extra_id_0> 'quick'.\",\n",
       " \"<extra_id_0> 'lyric'.\",\n",
       " \"<extra_id_0> 'band' - definition\",\n",
       " \"<extra_id_0> 'bat'.\",\n",
       " \"<extra_id_0>'side'.\",\n",
       " \"<extra_id_0>'scrub'.\",\n",
       " \"<extra_id_0>'rechargeable'\",\n",
       " \"<extra_id_0>'steamer'.\",\n",
       " \"<extra_id_0> 'pay'.\",\n",
       " \"<extra_id_0>'stolon'.\",\n",
       " \"<extra_id_0> 'caller'\",\n",
       " \"<extra_id_0> 'posterity'.\",\n",
       " \"<extra_id_0> 'negation'.\",\n",
       " \"<extra_id_0> 'dysphonia'\",\n",
       " \"<extra_id_0> 'polarity'.\",\n",
       " \"<extra_id_0>'receptor'.\",\n",
       " \"<extra_id_0> 'junk' Context:\",\n",
       " \"<extra_id_0> 'adapter' -\",\n",
       " \"<extra_id_0> 'limb'\",\n",
       " \"<extra_id_0> 'examine'.\",\n",
       " \"<extra_id_0> 'composition'.\",\n",
       " \"<extra_id_0> 'nana'.\",\n",
       " \"<extra_id_0> 'crossing'\",\n",
       " \"<extra_id_0> 'dominance'.\",\n",
       " \"<extra_id_0> 'opportunist'\",\n",
       " \"<extra_id_0> 'irritation'.\",\n",
       " \"<extra_id_0> 'hang'.\",\n",
       " \"<extra_id_0> 'proprietary'.\",\n",
       " \"<extra_id_0> 'number'.\",\n",
       " \"<extra_id_0> 'dominance'.\",\n",
       " \"<extra_id_0> 'execution'.\",\n",
       " \"<extra_id_0> 'pay attention to'\",\n",
       " \"<extra_id_0> 'astatine'.\",\n",
       " \"<extra_id_0> 'pragmatic'.\",\n",
       " \"<extra_id_0> 'jolt'\",\n",
       " \"<extra_id_0> 'chicken'.\",\n",
       " \"<extra_id_0> 'giveaway'.\",\n",
       " \"<extra_id_0> hepatitis '\",\n",
       " \"<extra_id_0> 'boldness'\",\n",
       " \"<extra_id_0> 'waterweed'\",\n",
       " \"<extra_id_0> 'take' Context:\",\n",
       " \"<extra_id_0> 'valet'.\",\n",
       " \"<extra_id_0> 'dress'.\",\n",
       " \"<extra_id_0> 'pen'.\",\n",
       " \"<extra_id_0>'mexican' Context:\",\n",
       " \"<extra_id_0>'sweetsop'.\",\n",
       " \"<extra_id_0> 'numb'.\",\n",
       " \"<extra_id_0>'serviceman'\",\n",
       " \"<extra_id_0> 'instrumentalism'.\",\n",
       " \"<extra_id_0> 'custom-built'\",\n",
       " \"<extra_id_0> 'heavy'.\",\n",
       " \"<extra_id_0> 'bufflehead'\",\n",
       " \"<extra_id_0> 'homebody'.\",\n",
       " \"<extra_id_0> 'bastion'\",\n",
       " \"<extra_id_0> 'probation'\",\n",
       " \"<extra_id_0>'rear'.\",\n",
       " \"<extra_id_0> 'afterword'.\",\n",
       " \"<extra_id_0> 'coverage' Context:\",\n",
       " \"<extra_id_0>'vetchling'.\",\n",
       " \"<extra_id_0> 'guard'.\",\n",
       " \"<extra_id_0> 'hang'.\",\n",
       " \"<extra_id_0> 'woodcraft'.\",\n",
       " \"<extra_id_0> 'gasp'\",\n",
       " \"<extra_id_0> 'biomarker'\",\n",
       " \"<extra_id_0> 'woodlark'\",\n",
       " \"<extra_id_0>'smallholding'.\",\n",
       " \"<extra_id_0> 'riparian'.\",\n",
       " \"<extra_id_0> 'puck'.\",\n",
       " \"<extra_id_0> 'antidepressant'\",\n",
       " \"<extra_id_0> 'payload'.\",\n",
       " \"<extra_id_0> 'chartism' -\",\n",
       " \"<extra_id_0> 'farthing'.\",\n",
       " \"<extra_id_0> 'painfulness'\",\n",
       " \"<extra_id_0> 'links' - Definition\",\n",
       " \"<extra_id_0> 'press'.\",\n",
       " \"<extra_id_0> 'brush'.\",\n",
       " \"<extra_id_0> 'thyroid'.\",\n",
       " \"<extra_id_0> 'nagging'.\",\n",
       " \"<extra_id_0> 'academy'.\",\n",
       " \"<extra_id_0> 'pearl'.\",\n",
       " \"<extra_id_0> 'piece'.\",\n",
       " \"<extra_id_0> 'promenade'.\",\n",
       " \"<extra_id_0> 'obviate'\",\n",
       " \"<extra_id_0> 'bitty' -\",\n",
       " \"<extra_id_0> 'upstairs'.\",\n",
       " \"<extra_id_0> 'upstairs'\",\n",
       " \"<extra_id_0> 'heap'\",\n",
       " \"<extra_id_0>'marry'\",\n",
       " \"<extra_id_0> 'pianissimo'.\",\n",
       " \"<extra_id_0> 'bandmaster'.\",\n",
       " \"<extra_id_0> 'pachysandra'\",\n",
       " \"<extra_id_0>'mounting'.\",\n",
       " \"<extra_id_0> 'heavy'.\",\n",
       " \"<extra_id_0> 'karakalpak'.\",\n",
       " \"<extra_id_0> 'honesty'.\",\n",
       " \"<extra_id_0> 'tigrayan'.\",\n",
       " \"<extra_id_0> 'polarity'.\",\n",
       " \"<extra_id_0>'mole'.\",\n",
       " \"<extra_id_0>'steeple'.\",\n",
       " \"<extra_id_0> 'tinny'.\",\n",
       " \"<extra_id_0> 'composition'.\",\n",
       " \"<extra_id_0> 'perfusate'\",\n",
       " \"<extra_id_0> 'quantification'.\",\n",
       " \"<extra_id_0>'sluggishness'\",\n",
       " \"<extra_id_0> 'canthus'.\",\n",
       " \"<extra_id_0> 'rake'.\",\n",
       " \"<extra_id_0> 'georgette'.\",\n",
       " \"<extra_id_0> 'locate',\",\n",
       " \"<extra_id_0>'repair'.\",\n",
       " \"<extra_id_0>'moderator'.\",\n",
       " \"<extra_id_0> 'dress' Context\",\n",
       " \"<extra_id_0> 'big' could be used\",\n",
       " \"<extra_id_0> 'transmutation'.\",\n",
       " \"<extra_id_0> 'high'.\",\n",
       " \"<extra_id_0> 'gage'.\",\n",
       " \"<extra_id_0> 'feeling'.\",\n",
       " \"<extra_id_0>'microscope'.\",\n",
       " \"<extra_id_0>'metoprolol'\",\n",
       " \"<extra_id_0> 'pot'.\",\n",
       " \"<extra_id_0> 'activity'.\",\n",
       " \"<extra_id_0>'moralist'.\",\n",
       " \"<extra_id_0> 'possessor'.\",\n",
       " \"<extra_id_0> 'ardor'\",\n",
       " \"<extra_id_0> 'intimacy'\",\n",
       " \"<extra_id_0> 'rataplan'.\",\n",
       " \"<extra_id_0> 'guidance'.\",\n",
       " \"<extra_id_0>'side'.\",\n",
       " \"<extra_id_0>'remission'.\",\n",
       " \"<extra_id_0> 'dockyard'.\",\n",
       " \"<extra_id_0> 'rotation' - Definitions\",\n",
       " \"<extra_id_0> 'texture'.\",\n",
       " \"<extra_id_0>'stance' Context:\",\n",
       " \"<extra_id_0> 'elevated'\",\n",
       " \"<extra_id_0> 'varnish'.\",\n",
       " \"<extra_id_0> 'ornithischian'\",\n",
       " \"<extra_id_0> 'talon' -\",\n",
       " \"<extra_id_0> 'back' could be used\",\n",
       " \"<extra_id_0> 'wave' Context:\",\n",
       " \"<extra_id_0> 'baby'.\",\n",
       " \"<extra_id_0> 'varsity'.\",\n",
       " \"<extra_id_0>'sweat'\",\n",
       " \"<extra_id_0> 'nine'.\",\n",
       " \"<extra_id_0> 'walk'.\",\n",
       " \"<extra_id_0> 'patronage'.\",\n",
       " \"<extra_id_0> 'fester'.\",\n",
       " '<extra_id_0> a-list.',\n",
       " \"<extra_id_0> 'dig'.\",\n",
       " \"<extra_id_0>'secretary' Context:\",\n",
       " \"<extra_id_0>'mounter'\",\n",
       " \"<extra_id_0> 'jehovah' -\",\n",
       " \"<extra_id_0> 'irreproducibility'\",\n",
       " \"<extra_id_0> 'oblivion'\",\n",
       " \"<extra_id_0> 'bleed'\",\n",
       " \"<extra_id_0> 'burrow'.\",\n",
       " \"<extra_id_0>'reflux'.\",\n",
       " \"<extra_id_0> 'admiral'.\",\n",
       " \"<extra_id_0> 'dak' Context:\",\n",
       " \"<extra_id_0> 'insolvent'.\",\n",
       " \"<extra_id_0> 'farrow'.\",\n",
       " \"<extra_id_0> 'fascia'\",\n",
       " \"<extra_id_0> 'quick'.\",\n",
       " \"<extra_id_0> 'why'.\",\n",
       " \"<extra_id_0> 'turkish'\",\n",
       " \"<extra_id_0> 'beery'.\",\n",
       " \"<extra_id_0>'readiness'.\",\n",
       " \"<extra_id_0> 'telugu',\",\n",
       " \"<extra_id_0> 'understatement'.\",\n",
       " \"<extra_id_0> 'bag'.\",\n",
       " \"<extra_id_0> 'flax'.\",\n",
       " '<extra_id_0> overflow - Definitions',\n",
       " \"<extra_id_0> 'dip'.\",\n",
       " \"<extra_id_0> 'guard'.\",\n",
       " \"<extra_id_0> 'productivity'.\",\n",
       " \"<extra_id_0> 'bag'.\",\n",
       " \"<extra_id_0> 'contemplation'\",\n",
       " \"<extra_id_0>'spirit' - Definition\",\n",
       " \"<extra_id_0> 'individualist'\",\n",
       " \"<extra_id_0>'rear'.\",\n",
       " \"<extra_id_0> 'hermaphrodite'\",\n",
       " \"<extra_id_0> 'crumble'.\",\n",
       " \"<extra_id_0> 'cornish'.\",\n",
       " \"<extra_id_0> 'devices'\",\n",
       " \"<extra_id_0> 'innocence'\",\n",
       " \"<extra_id_0> 'boatload'.\",\n",
       " \"<extra_id_0> 'flysheet'.\",\n",
       " \"<extra_id_0> 'firm'.\",\n",
       " \"<extra_id_0> 'hyperborean'\",\n",
       " \"<extra_id_0> 'back'.\",\n",
       " \"<extra_id_0> 'vasectomy'.\",\n",
       " \"<extra_id_0> 'opposite'\",\n",
       " \"<extra_id_0>'sharp'.\",\n",
       " '<extra_id_0> volley - definitions',\n",
       " '<extra_id_0> catholicos - definition',\n",
       " \"<extra_id_0> 'down' - Definition\",\n",
       " \"<extra_id_0> 'backbench'\",\n",
       " \"<extra_id_0> 'overflow'.\",\n",
       " \"<extra_id_0> 'vindication'\",\n",
       " \"<extra_id_0>'medical'.\",\n",
       " \"<extra_id_0>'min' could be used\",\n",
       " \"<extra_id_0> 'whole'.\",\n",
       " \"<extra_id_0> 'counterpoint'.\",\n",
       " \"<extra_id_0> 'indifference'\",\n",
       " \"<extra_id_0> 'rust' Context:\",\n",
       " \"<extra_id_0>'maraschino'.\",\n",
       " \"<extra_id_0> 'closure' Context\",\n",
       " \"<extra_id_0>'rear'.\",\n",
       " \"<extra_id_0> 'ionic'.\",\n",
       " \"<extra_id_0> 'joint'.\",\n",
       " \"<extra_id_0> 'bilge'.\",\n",
       " \"<extra_id_0>'shade'.\",\n",
       " \"<extra_id_0> 'back'.\",\n",
       " \"<extra_id_0> 'high' could be used\",\n",
       " \"<extra_id_0> 'operator'.\",\n",
       " \"<extra_id_0> 'numb'.\",\n",
       " \"<extra_id_0> 'compass'.\",\n",
       " \"<extra_id_0> 'new'.\",\n",
       " \"<extra_id_0> 'high'.\",\n",
       " \"<extra_id_0> 'electric'.\",\n",
       " \"<extra_id_0> 'roll-neck'\",\n",
       " \"<extra_id_0> 'winning'.\",\n",
       " \"<extra_id_0> 'crew' Context:\",\n",
       " \"<extra_id_0> 'joint' Context\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model definitions generated with a zero shot prompt\n",
    "model_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero shot - evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_untrained = rouge.compute(\n",
    "    predictions=model_definitions,\n",
    "    references=Definition[0:500],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.024649135536952492,\n",
       " 'rouge2': 0.0004,\n",
       " 'rougeL': 0.024444593530258393,\n",
       " 'rougeLsum': 0.024431370580890323}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    generate definition for the word based on context: \n",
      "    \n",
      "    Word: 'joint'\n",
      "    \n",
      "    Context: 'the pension companies will come up with a joint position on their participation in the pension reform .'\n",
      "    \n",
      "    Definition: \n"
     ]
    }
   ],
   "source": [
    "# Example of what the input to the model looks like in text\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [09:04<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "model_definitions = []\n",
    "\n",
    "for idx, w in tqdm(enumerate(words), total=len(words)):\n",
    "    prompt = f\"\"\"\n",
    "    generate definition for the word based on context: \n",
    "    \n",
    "    Word: '{words[1]}'\n",
    "    \n",
    "    Context: '{Context[1]}'\n",
    "    \n",
    "    Definition: {Definition[1]}\n",
    "    \n",
    "    \n",
    "    \n",
    "    generate definition for the word based on context: \n",
    "    \n",
    "    Word: '{words[4]}'\n",
    "    \n",
    "    Context: '{Context[4]}'\n",
    "    \n",
    "    Definition: {Definition[4]}\n",
    "    \n",
    "    \n",
    "    \n",
    "    generate definition for the word based on context: \n",
    "    \n",
    "    Word: '{w}'\n",
    "    \n",
    "    Context: '{Context[idx]}'\n",
    "    \n",
    "    Definition: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation = True, add_special_tokens=True)\n",
    "    \n",
    "    model_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    model_text_output = tokenizer.decode(model_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    model_definitions.append(model_text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    generate definition for the word based on context: \n",
      "    \n",
      "    Word: 'collapse'\n",
      "    \n",
      "    Context: 'institutions are rejecting warnings that house prices could collapse because low interest rates are likely to be held far into next year .'\n",
      "    \n",
      "    Definition: ( of a price or currency ) drop suddenly in value\n",
      "    \n",
      "    \n",
      "    \n",
      "    generate definition for the word based on context: \n",
      "    \n",
      "    Word: 'electrometer'\n",
      "    \n",
      "    Context: 'shortly after antoine becquerel and others developed the electrometer , john mothée gaugain made the first precise measurements of pyroelectric charges in 1859 .'\n",
      "    \n",
      "    Definition: an instrument for measuring electrical potential without drawing any current from the circuit .\n",
      "    \n",
      "    \n",
      "    \n",
      "    generate definition for the word based on context: \n",
      "    \n",
      "    Word: 'joint'\n",
      "    \n",
      "    Context: 'the pension companies will come up with a joint position on their participation in the pension reform .'\n",
      "    \n",
      "    Definition: \n"
     ]
    }
   ],
   "source": [
    "# What the prompt looks like as input\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_untrained = rouge.compute(\n",
    "    predictions=model_definitions,\n",
    "    references=Definition[0:500],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.08368350951693024,\n",
       " 'rouge2': 0.0024155178155178154,\n",
       " 'rougeL': 0.08024635301846923,\n",
       " 'rougeLsum': 0.08079050518717734}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<extra_id_0> a few hundred years ago.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a throw in.',\n",
       " '<extra_id_0> a currency..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a phrase which means',\n",
       " '<extra_id_0> a joint session of congress',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a sharp bark of a dog',\n",
       " '<extra_id_0> a zebra fish.',\n",
       " '<extra_id_0> a financial crisis.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> income-tax return.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>....',\n",
       " '<extra_id_0> a terrestrial ball.',\n",
       " '<extra_id_0> a slight increase in value',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a political entity.',\n",
       " '<extra_id_0> a flood of flags.',\n",
       " '<extra_id_0> a mortgage.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a heat.',\n",
       " '<extra_id_0> a surgical emergency.',\n",
       " '<extra_id_0>, a sheep.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a certain amount of',\n",
       " \"<extra_id_0> a higher.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a good movie house should have a movie house',\n",
       " '<extra_id_0>, the electricity generated',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a bitter struggle.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a false claim.',\n",
       " '<extra_id_0> a political debate.',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, the opposite sex.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a slight increase in.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, which causes.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a cycle of deposition and redeposition',\n",
       " '<extra_id_0> a funny walk.',\n",
       " \"<extra_id_0> i want to go home now'\",\n",
       " '<extra_id_0>, a british reserve.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0> a higher.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a mighty heave.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, winning is not everything.',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, he gets his brains from his father',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a few hundred.',\n",
       " '<extra_id_0> a shimmer of a',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a mathematical calculation of.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a ring.',\n",
       " '<extra_id_0>, a foreign national.',\n",
       " '<extra_id_0> a carrying a rock away',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a stunning garden.',\n",
       " '<extra_id_0> a tuffet eating some whey',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a threat to the public.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, the pharynx',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a higher amount of electricity',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0>, a slight dip.',\n",
       " '<extra_id_0>, a straitened',\n",
       " '<extra_id_0> a very nice charging system.',\n",
       " '<extra_id_0> a financial crisis.',\n",
       " '<extra_id_0> a timeline.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a serious work of art',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a certain amount of.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0> a disaster.' Definition:\",\n",
       " '<extra_id_0> a junk habit.',\n",
       " '<extra_id_0>, a myth.',\n",
       " '<extra_id_0>, i am a.',\n",
       " '<extra_id_0> a stadium.',\n",
       " '<extra_id_0> a means of a',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0> a currency.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>....',\n",
       " '<extra_id_0> a financial crisis.',\n",
       " '<extra_id_0>, a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a heavy investor.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a phrase which means',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0>, a pregnancy.',\n",
       " '<extra_id_0> a toyota saloon.',\n",
       " '<extra_id_0> a sling of arrows',\n",
       " '<extra_id_0> a dip in the road.',\n",
       " '<extra_id_0>, the inertial mass',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a chemical compound.',\n",
       " '<extra_id_0>, which is called.',\n",
       " \"<extra_id_0> a higher.' Definition:\",\n",
       " '<extra_id_0> a rugby match.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> these colors clash.',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a wick.',\n",
       " '<extra_id_0> a fast pace of electricity.',\n",
       " '<extra_id_0>, a climate.',\n",
       " '<extra_id_0> a suitable.',\n",
       " '<extra_id_0> a mosquito.',\n",
       " '<extra_id_0> a roast chicken and crispy',\n",
       " '<extra_id_0> a very weak economy',\n",
       " '<extra_id_0>, the product acts like a solid',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a lyric stage.',\n",
       " '<extra_id_0> a bottle of sweet dessert wine',\n",
       " '<extra_id_0>, a spaniel',\n",
       " '<extra_id_0> a higher.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a shrine.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a higher amount of.',\n",
       " '<extra_id_0>, a surgical procedure',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a very lively world',\n",
       " '<extra_id_0> a chinese porcelain',\n",
       " '<extra_id_0> a chicken app.',\n",
       " '<extra_id_0> a slight increase in.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a female.',\n",
       " '<extra_id_0> a stomach dropped.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, i need to scry for the',\n",
       " '<extra_id_0> a political attitude.',\n",
       " '<extra_id_0> a dress shoes.',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a semiconductor device.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a financial crisis.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a currency.',\n",
       " '<extra_id_0> a society.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, which could.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a penny-farthing race',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a baby.',\n",
       " '<extra_id_0>, a failure.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a political debate.',\n",
       " '<extra_id_0> a political operative.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0> a higher.' Definition:\",\n",
       " '<extra_id_0>, a sheep.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a sheep country',\n",
       " '<extra_id_0> a slight deodorize',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a species.',\n",
       " '<extra_id_0> a rook.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a financial crisis.',\n",
       " '<extra_id_0> a jeremiad against any form of government',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0> a 'hang wallpaper'\",\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0> a passenger.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a scatter of.',\n",
       " '<extra_id_0> a mandarin tree.',\n",
       " '<extra_id_0>, a student of the occult',\n",
       " '<extra_id_0> a higher amount of electricity',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a species.',\n",
       " '<extra_id_0> a broadcaster.',\n",
       " '<extra_id_0> a thumb is absent',\n",
       " '<extra_id_0>, which means,',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a '.\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a slight increase in value',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a healthy cholesterol homeostasis',\n",
       " '<extra_id_0> a smoke.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, iodine is a',\n",
       " '<extra_id_0> a phrase.',\n",
       " '<extra_id_0> a structural discontinuity between the shield',\n",
       " '<extra_id_0> a leap of 10 feet',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0>, a very weak.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a dangerous.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a deadline.',\n",
       " '<extra_id_0> a sharp stab of pain.',\n",
       " '<extra_id_0>, a debate.',\n",
       " \"<extra_id_0> a soccer.' Definition:\",\n",
       " '<extra_id_0> a slight increase in value',\n",
       " '<extra_id_0> a useful refresher.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a quick inspection.',\n",
       " '<extra_id_0> a poetry.',\n",
       " '<extra_id_0>, a rhythm.',\n",
       " \"<extra_id_0> a 'ball' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a sheep running outside the woods',\n",
       " '<extra_id_0> a rechargeable battery.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0> a visit.' Definition:\",\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " \"<extra_id_0> a 'caller'\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a quantity of.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0> a'a '\",\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a voltage.',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>. generate definition for the word based on context:',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a marriage.',\n",
       " '<extra_id_0> a political candidate.',\n",
       " '<extra_id_0> a negative.',\n",
       " '<extra_id_0>, i would.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a currency.',\n",
       " '<extra_id_0> a competitive advantage.',\n",
       " '<extra_id_0>, the kernel generate definition for:',\n",
       " '<extra_id_0>, pay attention to pay attention to',\n",
       " '<extra_id_0> a chemical element.',\n",
       " '<extra_id_0> a political candidate.',\n",
       " '<extra_id_0> a jolt.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0> a giveaway.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a dress dinner.',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a grain of wool',\n",
       " \"<extra_id_0> a household.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a novel superior to,',\n",
       " '<extra_id_0> a higher income.',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a gasp and fainted',\n",
       " '<extra_id_0> a negative.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0> a'a '\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a passenger seat configuration of 20 seats',\n",
       " \"<extra_id_0> a currency.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a pregnancy.',\n",
       " \"<extra_id_0> a'a '\",\n",
       " '<extra_id_0> a stainless steel tank.',\n",
       " '<extra_id_0>, a brush.',\n",
       " '<extra_id_0> a flap-like cartilage',\n",
       " \"<extra_id_0> a'a '\",\n",
       " '<extra_id_0> a sign reads mugen high school',\n",
       " '<extra_id_0> a pearl of sweat roll down my face',\n",
       " '<extra_id_0> a very interesting piece on iran',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a ladder.',\n",
       " '<extra_id_0>, a staircase',\n",
       " '<extra_id_0> a candle.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0> a currency.' Definition:\",\n",
       " '<extra_id_0> hydrogen. hydrogen.',\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a currency.',\n",
       " '<extra_id_0> a semiconductor device.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0> a higher.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a. generate definition for the word',\n",
       " \"<extra_id_0> a currency.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a sluggishness of the economy',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a slope.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, the building was in good repair'\",\n",
       " '<extra_id_0> a few weeks.',\n",
       " '<extra_id_0> a swimsuit.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a blockade.',\n",
       " '<extra_id_0>, a genuine feeling.',\n",
       " '<extra_id_0> a measurement of electrical potential.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a higher level of activity.',\n",
       " '<extra_id_0> a very useful.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a revolutionary ardor.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a swollen sky.',\n",
       " '<extra_id_0> a surgical procedure.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a sampling of.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a texture.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a higher inflation rate.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a higher.',\n",
       " \"<extra_id_0> rabbits.' Definition:\",\n",
       " '<extra_id_0> a higher amount of electricity',\n",
       " '<extra_id_0> a sheep poured off his brow',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a financial crisis.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a chemical salt.',\n",
       " '<extra_id_0> a secretary.',\n",
       " '<extra_id_0> a staircase.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0> a 'bleed'\",\n",
       " \"<extra_id_0> a'a '\",\n",
       " '<extra_id_0>, i would not have',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a financial crisis.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0> a muscle.' Definition:\",\n",
       " '<extra_id_0> a prison.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a foreign language.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a false flax',\n",
       " \"<extra_id_0> a currency.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, the basket your player is.',\n",
       " '<extra_id_0> a given task.',\n",
       " '<extra_id_0> a few pheasants',\n",
       " '<extra_id_0> a religious faith.',\n",
       " '<extra_id_0>, a fuel.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0> a weapon.',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a currency.',\n",
       " \"<extra_id_0> a household.' Definition:\",\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, a debt.',\n",
       " '<extra_id_0> a slight increase in value',\n",
       " '<extra_id_0> a firm grasp.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, leaves.',\n",
       " '<extra_id_0>....',\n",
       " '<extra_id_0> a weapon.',\n",
       " '<extra_id_0> a king.',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>. generate definition for the word based on context',\n",
       " '<extra_id_0> a significant increase in electricity prices',\n",
       " \"<extra_id_0> a'a '\",\n",
       " \"<extra_id_0> a'medical treatment' Definition:\",\n",
       " '<extra_id_0>....',\n",
       " '<extra_id_0> a whole week.',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0>, a..',\n",
       " \"<extra_id_0> a higher.' Definition:\",\n",
       " '<extra_id_0>....',\n",
       " '<extra_id_0> a financial crisis.',\n",
       " '<extra_id_0> a higher.',\n",
       " '<extra_id_0> a dialect of a dialect',\n",
       " '<extra_id_0>, the stiffness of a car',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, a few days later',\n",
       " '<extra_id_0> a species of a species',\n",
       " '<extra_id_0>, the operator of the switchboard',\n",
       " '<extra_id_0>, a..',\n",
       " '<extra_id_0>, within the compass of education',\n",
       " \"<extra_id_0>, a.' Definition:\",\n",
       " '<extra_id_0>, which is a.',\n",
       " '<extra_id_0> a very atmospheric atmosphere',\n",
       " '<extra_id_0> a currency.',\n",
       " '<extra_id_0> a winning personality.',\n",
       " '<extra_id_0> a slight increase in value',\n",
       " '<extra_id_0> a financial crisis.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some examples of what the model generates with few shot learning\n",
    "model_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
